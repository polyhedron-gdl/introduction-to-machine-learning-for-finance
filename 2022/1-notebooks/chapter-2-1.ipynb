{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/polyhedron-gdl/introduction-to-machine-learning-for-finance/blob/main/2022/1-notebooks/chapter-2-1.ipynb\">\n",
    "        <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "Raw data rarely comes in the form and shape that is necessary for the optimal\n",
    "performance of a learning algorithm. On the other hand, the success of a machine learning algorithm highly depends on the quality of the data fed into the model. Real-world data is often dirty containing outliers, missing values, wrong data types, irrelevant features, or non-standardized data. The presence of any of these will prevent the machine learning model to properly learn. For this reason, transforming raw data into a useful format is an essential stage in the machine learning process. Therefore,\n",
    "it is absolutely critical to ensure that we examine and preprocess a dataset before\n",
    "we feed it to a learning algorithm. In this section, we will discuss the essential data\n",
    "preprocessing techniques that will help us to build good machine learning models.\n",
    "\n",
    "The topics that we will cover in this lesson are as follows:\n",
    "\n",
    "- Removing and imputing missing values from the dataset\n",
    "- Getting categorical data into shape for machine learning algorithms\n",
    "- Selecting relevant features for the model construction\n",
    "- Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "\n",
    "The real-world data often has a lot of missing values. The cause of missing values can be data corruption or failure to record data. The handling of missing data is very important during the preprocessing of the dataset as many machine learning algorithms do not support missing values.\n",
    "\n",
    "\n",
    "Let's create\n",
    "a simple example data frame from a comma-separated values (CSV) file to get\n",
    "a better grasp of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   NaN  8.0\n",
       "2  10.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "csv_data = \\\n",
    "    '''A,B,C,D\n",
    "    1.0,2.0,3.0,4.0\n",
    "    5.0,6.0,,8.0\n",
    "    10.0,11.0,12.0,'''\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Rows with Missing Values \n",
    "\n",
    "One of the easiest ways to deal with missing data is simply to remove the\n",
    "corresponding features (columns) or training examples (rows) from the dataset\n",
    "entirely. Missing values can be handled by deleting the rows or columns having null values. If columns have more than half of the rows as null then the entire column can be dropped. The rows which are having one or more columns values as null can also be dropped.\n",
    "\n",
    "Remember that, in pandas, rows with missing values can easily be dropped via the dropna method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  1.0  2.0  3.0  4.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the removal of missing data seems to be a convenient approach, it also\n",
    "comes with certain disadvantages; for example, we may end up removing too\n",
    "many samples, which will make a reliable analysis impossible. Or, if we remove too\n",
    "many feature columns, we will run the risk of losing valuable information that our\n",
    "classifier needs to discriminate between classes. In the next section, we will look\n",
    "at one of the most commonly used alternatives for dealing with missing values:\n",
    "interpolation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- A model trained with the removal of all missing values creates a robust model.\n",
    "\n",
    "**Cons**:\n",
    "- Loss of a lot of information.\n",
    "- Works poorly if the percentage of missing values is excessive in comparison to the complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values\n",
    "\n",
    "One of the most common interpolation\n",
    "techniques is called **imputation**, where we simply replace the missing value with\n",
    "the mean value of the entire feature column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**scikit-learn - SimpleImputer**\n",
    ">\n",
    ">A convenient way to achieve this is by\n",
    ">using the **SimpleImputer** class from scikit-learn. Scikit-learn, infact,  has built-in methods to perform these  preprocessing steps. For example, the `SimpleImputer()` fills in missing values using a method of your choice (see the code >below). The Scikit-learn documentation lists the full options for data preprocessing [here](https://scikit-learn.org/stable/modules/preprocessing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  2. ,  3. ,  4. ],\n",
       "       [ 5. ,  6. ,  7.5,  8. ],\n",
       "       [10. , 11. , 12. ,  6. ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imr = imr.fit(df.values)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, an even more convenient way to impute missing values is by using\n",
    "pandas' **fillna** method and providing an imputation method as an argument. For\n",
    "example, using pandas, we could achieve the same mean imputation directly in the\n",
    "DataFrame object via the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C    D\n",
       "0   1.0   2.0   3.0  4.0\n",
       "1   5.0   6.0   7.5  8.0\n",
       "2  10.0  11.0  12.0  6.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- Prevent data loss which results in deletion of rows or columns\n",
    "- Works well with a small dataset and is easy to implement.\n",
    "\n",
    "**Cons**:\n",
    "- Works only with numerical continuous variables.\n",
    "- Can cause data leakage\n",
    "- Do not factor the covariance between features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Delete Zero-Variance Predictors\n",
    "\n",
    "Zero-variance predictors refer to input features that contain a single value across the entire spectrum of observations. Accordingly, they do not add any value to the prediction algorithm since the target variable is not affected by the input value, making them redundant. Some ML algorithms might also run into unexpected errors or output wrong results.\n",
    "Pandas provides a short and sweet function to count and list the number of unique values in each column of a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D     E\n",
       "0  1.0   2.0   3.0  4.0  42.0\n",
       "1  5.0   6.0   7.0  8.0  42.0\n",
       "2  9.0  10.0  11.0  8.0  42.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = \\\n",
    "    '''A,B,C,D,E\n",
    "    1.0,2.0,3.0,4.0,42.0\n",
    "    5.0,6.0,7.0,8.0,42.0\n",
    "    9.0,10.0,11.0,8.0,42.0'''\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    3\n",
       "B    3\n",
       "C    3\n",
       "D    2\n",
       "E    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will drop all columns that have a single value and update the df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A     B     C    D\n",
      "0  1.0   2.0   3.0  4.0\n",
      "1  5.0   6.0   7.0  8.0\n",
      "2  9.0  10.0  11.0  8.0\n",
      "     A     B     C    D     E\n",
      "0  1.0   2.0   3.0  4.0  42.0\n",
      "1  5.0   6.0   7.0  8.0  42.0\n",
      "2  9.0  10.0  11.0  8.0  42.0\n"
     ]
    }
   ],
   "source": [
    "df2 = df.drop(columns = df.columns[df.nunique() == 1],\n",
    "    inplace = False)\n",
    "print(df2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D\n",
       "0  1.0   2.0   3.0  4.0\n",
       "1  5.0   6.0   7.0  8.0\n",
       "2  9.0  10.0  11.0  8.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = df.columns[df.nunique() == 1],\n",
    "    inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data is a form of data that takes on values within a finite set of discrete classes. It is difficult to count or measure categorical data using numbers and therefore they are divided into categories. \n",
    "\n",
    "When we are talking about categorical data, we have to further distinguish between\n",
    "**ordinal** and **nominal** features. \n",
    "\n",
    "**Ordinal** features can be understood as categorical\n",
    "values that *can be sorted or ordered*. For example, t-shirt size would be an ordinal\n",
    "feature, because we can define an order: XL > L > M. \n",
    "\n",
    "In contrast, **nominal** features\n",
    "don't imply any order and, to continue with the previous example, we could think\n",
    "of t-shirt color as a nominal feature since it typically doesn't make sense to say that,\n",
    "for example, red is larger than blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we explore different techniques for handling such categorical data, let's create a new DataFrame to illustrate the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class2\n",
       "1    red    L   13.5     class1\n",
       "2   blue   XL   15.3     class2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    ['green', 'M', 10.1, 'class2'],\n",
    "    ['red', 'L', 13.5, 'class1'],\n",
    "    ['blue', 'XL', 15.3, 'class2']])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **REMIND - FEATURES AND LABELS**\n",
    "> ***\n",
    "> Remember that in machine learning, you have **features** and **labels**. *The features are the **descriptive** attributes*, and *the \n",
    "> label is what you're attempting to predict or forecast*. In this simple example, COLOR, SIZE and PRICE are **features** while \n",
    "> CLASSLABEL is the field that contains the **label** > of the corresponding record.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the learning algorithm interprets the ordinal features correctly,\n",
    "we need to convert the categorical string values into integers. Unfortunately, there\n",
    "is no convenient function that can automatically derive the correct order of the labels\n",
    "of our size feature, so we have to define the mapping manually. In the following\n",
    "simple example, let's assume that we know the numerical difference between\n",
    "features, for example, XL = L + 1 = M + 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.1     class2\n",
       "1    red     2   13.5     class1\n",
       "2   blue     3   15.3     class2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_mapping = {'XL': 3,'L': 2,'M': 1}\n",
    "\n",
    "df2 = df.copy()\n",
    "df2['size'] = df2['size'].map(size_mapping)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Preprocessing : sklearn.preprocessing**\n",
    "> \n",
    "> Among some commonly used preprocessing tasks come `OneHotEncoder`, `StandardScaler`, `MinMaxScaler`, etc. These are respectively for encoding of the categorical features into a one-hot numeric array, standardization of the features and scaling each feature to a given range. Many other preprocessing methods are built-in this module.\n",
    "We can import this module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green   0.0   10.1     class2\n",
       "1    red   1.0   13.5     class1\n",
       "2   blue   2.0   15.3     class2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal = OrdinalEncoder(categories=[['M', 'L', 'XL']])\n",
    "df3['size'] = ordinal.fit_transform(df3[['size']])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Class Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning libraries require that class labels are encoded as integer\n",
    "values. Although most estimators for classification in scikit-learn convert class\n",
    "labels to integers internally, it is considered good practice to provide class labels as\n",
    "integer arrays to avoid technical glitches. To encode the class labels, we can use an\n",
    "approach similar to the mapping of ordinal features discussed previously. We need\n",
    "to remember that class labels are not ordinal, and it doesn't matter which integer\n",
    "number we assign to a particular string label. Thus, we can simply enumerate\n",
    "the class labels, starting at 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **REMIND - enumerate() method in Python**\n",
    ">***\n",
    ">\n",
    "> `Enumerate()` method adds a counter to an iterable and returns it in a form of enumerating object. This enumerated object can then be used directly for loops or converted into a list of tuples using the `list()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class1': 0, 'class2': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(df['classlabel']))}\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use the mapping dictionary to transform the class labels into integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price  classlabel\n",
       "0  green    M   10.1           1\n",
       "1    red    L   13.5           0\n",
       "2   blue   XL   15.3           1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classlabel'] = df['classlabel'].map(class_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reverse the key-value pairs in the mapping dictionary as follows to map the\n",
    "converted class labels back to the original string representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class2\n",
       "1    red    L   13.5     class1\n",
       "2   blue   XL   15.3     class2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "df['classlabel'] = df['classlabel'].map(inv_class_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, there is a convenient LabelEncoder class directly implemented in\n",
    "scikit-learn to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df['classlabel'].values)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no a natural order we have to resort to a different approach that is to use the technique called **one-hot encoding**.  The idea behind this approach is to create a new dummy feature for each\n",
    "unique value in the nominal feature column. Here, we would convert the color\n",
    "feature into three new features: *blue*, *green*, and *red*. Binary values can then be used\n",
    "to indicate the particular color of an example; for example, a blue example can be\n",
    "encoded as *blue=1, green=0, red=0*. To perform this transformation, we can use the\n",
    "OneHotEncoder that is implemented in scikit-learn's preprocessing module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = df[['color', 'size', 'price']].values\n",
    "color_ohe = OneHotEncoder()\n",
    "color_ohe.fit_transform(X[:, 0].reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even more convenient way to create those dummy features via one-hot encoding\n",
    "is to use the get_dummies method implemented in pandas. Applied to a DataFrame,\n",
    "the get_dummies method will only convert string columns and leave all other\n",
    "columns unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "      <th>size_L</th>\n",
       "      <th>size_M</th>\n",
       "      <th>size_XL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  color_blue  color_green  color_red  size_L  size_M  size_XL\n",
       "0   10.1           0            1          0       0       1        0\n",
       "1   13.5           0            0          1       1       0        0\n",
       "2   15.3           1            0          0       0       0        1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df[['price', 'color', 'size']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning algorithms require that the selected features are on\n",
    "the same scale for optimal performance, this process is called \"Feature Normalization\" and is the subject of this paragraph.\n",
    "\n",
    "Data Normalization is a common practice in machine learning which consists of transforming numeric columns to a common scale. In machine learning, some feature values differ from others multiple times. The features with higher values will dominate the leaning process. However, it does not mean those variables are more important to predict the outcome of the model. Data normalization transforms multiscaled data to the same scale. After normalization, all variables have a similar influence on the model, improving the stability and performance of the learning algorithm.\n",
    "\n",
    "There are multiple normalization techniques in statistics. In this notebook, we will cover the most important ones:\n",
    "\n",
    "- The maximum absolute scaling\n",
    "- The min-max feature scaling\n",
    "- The z-score method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximum absolute scaling\n",
    "\n",
    "The maximum absolute scaling rescales each feature between -1 and 1 by dividing every observation by its maximum absolute value.\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old}}{\\max \\vert x_{old} \\vert}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The min-max feature scaling\n",
    "\n",
    "The min-max approach (often called normalization) rescales the feature to a fixed range of [0,1] by subtracting the minimum value of the feature and then dividing by the range:\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old}-x_{min}}{x_{max}-x_{min}}\n",
    "$$\n",
    "\n",
    "The min-max scaling procedure is implemented in scikit-learn and can be used as\n",
    "follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we have to load the file 'salary_vs_age_1.csv'\n",
    "#\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Salary\n",
      "0   25  135000\n",
      "1   27  105000\n",
      "2   30  105000\n",
      "3   35  220000\n",
      "4   40  300000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age2</th>\n",
       "      <th>Age3</th>\n",
       "      <th>Age4</th>\n",
       "      <th>Age5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>25</td>\n",
       "      <td>625</td>\n",
       "      <td>15625</td>\n",
       "      <td>390625</td>\n",
       "      <td>9765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.0</td>\n",
       "      <td>27</td>\n",
       "      <td>729</td>\n",
       "      <td>19683</td>\n",
       "      <td>531441</td>\n",
       "      <td>14348907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.0</td>\n",
       "      <td>30</td>\n",
       "      <td>900</td>\n",
       "      <td>27000</td>\n",
       "      <td>810000</td>\n",
       "      <td>24300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1225</td>\n",
       "      <td>42875</td>\n",
       "      <td>1500625</td>\n",
       "      <td>52521875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1600</td>\n",
       "      <td>64000</td>\n",
       "      <td>2560000</td>\n",
       "      <td>102400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270.0</td>\n",
       "      <td>45</td>\n",
       "      <td>2025</td>\n",
       "      <td>91125</td>\n",
       "      <td>4100625</td>\n",
       "      <td>184528125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265.0</td>\n",
       "      <td>50</td>\n",
       "      <td>2500</td>\n",
       "      <td>125000</td>\n",
       "      <td>6250000</td>\n",
       "      <td>312500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260.0</td>\n",
       "      <td>55</td>\n",
       "      <td>3025</td>\n",
       "      <td>166375</td>\n",
       "      <td>9150625</td>\n",
       "      <td>503284375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>240.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3600</td>\n",
       "      <td>216000</td>\n",
       "      <td>12960000</td>\n",
       "      <td>777600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>265.0</td>\n",
       "      <td>65</td>\n",
       "      <td>4225</td>\n",
       "      <td>274625</td>\n",
       "      <td>17850625</td>\n",
       "      <td>1160290625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary  Age  Age2    Age3      Age4        Age5\n",
       "0   135.0   25   625   15625    390625     9765625\n",
       "1   105.0   27   729   19683    531441    14348907\n",
       "2   105.0   30   900   27000    810000    24300000\n",
       "3   220.0   35  1225   42875   1500625    52521875\n",
       "4   300.0   40  1600   64000   2560000   102400000\n",
       "5   270.0   45  2025   91125   4100625   184528125\n",
       "6   265.0   50  2500  125000   6250000   312500000\n",
       "7   260.0   55  3025  166375   9150625   503284375\n",
       "8   240.0   60  3600  216000  12960000   777600000\n",
       "9   265.0   65  4225  274625  17850625  1160290625"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pandas libraries with alias 'pd' \n",
    "import pandas as pd \n",
    "# Read data from file 'salary_vs_age_1.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, with read_table \n",
    "df1 = pd.read_table(path + \"salary_vs_age_1.csv\", sep=\";\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "print(df1.head())\n",
    "\n",
    "columns_titles = [\"Salary\",\"Age\"]\n",
    "df2=df1.reindex(columns=columns_titles)\n",
    "df2\n",
    "\n",
    "df2['Salary'] = df2['Salary']/1000 \n",
    "df2['Age2']=df2['Age']**2\n",
    "df2['Age3']=df2['Age']**3\n",
    "df2['Age4']=df2['Age']**4\n",
    "df2['Age5']=df2['Age']**5\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.043919</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.105212</td>\n",
       "      <td>0.063574</td>\n",
       "      <td>0.037162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.186776</td>\n",
       "      <td>0.124248</td>\n",
       "      <td>0.080515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.291506</td>\n",
       "      <td>0.212486</td>\n",
       "      <td>0.151898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.422297</td>\n",
       "      <td>0.335588</td>\n",
       "      <td>0.263127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>0.501718</td>\n",
       "      <td>0.428951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.826389</td>\n",
       "      <td>0.773649</td>\n",
       "      <td>0.719895</td>\n",
       "      <td>0.667377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1         2         3         4         5\n",
       "0  0.153846  0.000  0.000000  0.000000  0.000000  0.000000\n",
       "1  0.000000  0.050  0.028889  0.015668  0.008065  0.003984\n",
       "2  0.000000  0.125  0.076389  0.043919  0.024019  0.012633\n",
       "3  0.589744  0.250  0.166667  0.105212  0.063574  0.037162\n",
       "4  1.000000  0.375  0.270833  0.186776  0.124248  0.080515\n",
       "5  0.846154  0.500  0.388889  0.291506  0.212486  0.151898\n",
       "6  0.820513  0.625  0.520833  0.422297  0.335588  0.263127\n",
       "7  0.794872  0.750  0.666667  0.582046  0.501718  0.428951\n",
       "8  0.692308  0.875  0.826389  0.773649  0.719895  0.667377\n",
       "9  0.820513  1.000  1.000000  1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "df3 = pd.DataFrame(mms.fit_transform(df2))\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score\n",
    "\n",
    "The **z-score** method (often called **standardization**) transforms the data into a distribution with a mean of 0 and a standard deviation of 1. Each standardized value is computed by subtracting the mean of the corresponding feature and then dividing by the standard deviation.\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old} - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Unlike min-max scaling, the z-score does not rescale the feature to a fixed range. The z-score typically ranges from -3.00 to 3.00 (more than 99% of the data) if the input is normally distributed.\n",
    "\n",
    "It is important to bear in mind that z-scores are not necessarily normally distributed. They just scale the data and follow the same distribution as the original input. This transformed distribution has a mean of 0 and a standard deviation of 1 and is going to be the standard normal distribution only if the input feature follows a normal distribution.\n",
    "\n",
    "Standardization can easily be achieved by using the built-in NumPy methods mean\n",
    "and std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.39443338 -1.19522861 -1.19522861 -0.19920477  0.          0.\n",
      "  0.39840954  0.5976143   1.19522861  1.79284291]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([6, 7, 7, 12, 13, 13, 15, 16, 19, 22])\n",
    "\n",
    "X_std = np.copy(X)\n",
    "X_std = (X - X.mean()) / X.std()\n",
    "\n",
    "print(X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or simply using the specific function of the stats module of scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.39443338, -1.19522861, -1.19522861, -0.19920477,  0.        ,\n",
       "        0.        ,  0.39840954,  0.5976143 ,  1.19522861,  1.79284291])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.zscore(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization is very useful with gradient descent learning. In this case\n",
    "the optimizer has to go through fewer steps to find a good or optimal solution (the\n",
    "global cost minimum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chapter-2-1_pic_0.png](./pic/chapter-2-1_pic_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the MinMaxScaler class, scikit-learn also implements a class for\n",
    "standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.170242</td>\n",
       "      <td>-1.359724</td>\n",
       "      <td>-1.189131</td>\n",
       "      <td>-1.041783</td>\n",
       "      <td>-0.920815</td>\n",
       "      <td>-0.824435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.601005</td>\n",
       "      <td>-1.210304</td>\n",
       "      <td>-1.102065</td>\n",
       "      <td>-0.994071</td>\n",
       "      <td>-0.895974</td>\n",
       "      <td>-0.812022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.601005</td>\n",
       "      <td>-0.986174</td>\n",
       "      <td>-0.958907</td>\n",
       "      <td>-0.908042</td>\n",
       "      <td>-0.846835</td>\n",
       "      <td>-0.785069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050256</td>\n",
       "      <td>-0.612623</td>\n",
       "      <td>-0.686823</td>\n",
       "      <td>-0.721391</td>\n",
       "      <td>-0.725003</td>\n",
       "      <td>-0.708630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.198959</td>\n",
       "      <td>-0.239072</td>\n",
       "      <td>-0.372880</td>\n",
       "      <td>-0.473014</td>\n",
       "      <td>-0.538122</td>\n",
       "      <td>-0.573535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.768195</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>-0.017078</td>\n",
       "      <td>-0.154092</td>\n",
       "      <td>-0.266345</td>\n",
       "      <td>-0.351091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.696401</td>\n",
       "      <td>0.508029</td>\n",
       "      <td>0.380582</td>\n",
       "      <td>0.244194</td>\n",
       "      <td>0.112820</td>\n",
       "      <td>-0.004480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.624608</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.820102</td>\n",
       "      <td>0.730661</td>\n",
       "      <td>0.624511</td>\n",
       "      <td>0.512260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.337432</td>\n",
       "      <td>1.255130</td>\n",
       "      <td>1.301481</td>\n",
       "      <td>1.314127</td>\n",
       "      <td>1.296512</td>\n",
       "      <td>1.255243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.696401</td>\n",
       "      <td>1.628681</td>\n",
       "      <td>1.824719</td>\n",
       "      <td>2.003411</td>\n",
       "      <td>2.159252</td>\n",
       "      <td>2.291760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0 -1.170242 -1.359724 -1.189131 -1.041783 -0.920815 -0.824435\n",
       "1 -1.601005 -1.210304 -1.102065 -0.994071 -0.895974 -0.812022\n",
       "2 -1.601005 -0.986174 -0.958907 -0.908042 -0.846835 -0.785069\n",
       "3  0.050256 -0.612623 -0.686823 -0.721391 -0.725003 -0.708630\n",
       "4  1.198959 -0.239072 -0.372880 -0.473014 -0.538122 -0.573535\n",
       "5  0.768195  0.134478 -0.017078 -0.154092 -0.266345 -0.351091\n",
       "6  0.696401  0.508029  0.380582  0.244194  0.112820 -0.004480\n",
       "7  0.624608  0.881579  0.820102  0.730661  0.624511  0.512260\n",
       "8  0.337432  1.255130  1.301481  1.314127  1.296512  1.255243\n",
       "9  0.696401  1.628681  1.824719  2.003411  2.159252  2.291760"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "df4 = pd.DataFrame(stdsc.fit_transform(df2))\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA as a concept is useful for measuring risk arising from a set of correlated market variables. For example, interest rates that are quoted in the market have correlation to each other. Thus, an interest rate for tenor 1Y is not independent of interest rate for tenor say 3Y. There is always some degree of correlation between all the tenor points with each other. To achieve this objective, the PCA model computes a set of variables that are called as Principal components (PCs). PCA is a model which involves transforming a set of observations (i.e. interest rate time series in our case) into a set of uncorrelated variables called as the PCs. This transformation behaves in way such that the first PC explains the largest possible variance, and this accounts for majority of the variability in the data. Each succeeding component in turn explains the highest possible variance while at the same time following the condition of orthogonality to each of the preceding PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chapter-2-1_pic_1.png](./pic/chapter-2-1_pic_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting PCs computed by the model are uncorrelated to each other, thereby allowing them to be used independently with respect to each other. Individual PCs are calculated using the concept of Eigen values again a concept of linear algebra. PCs represent directions of the data that explain the maximum amount of variance, i.e. the vectors that capture most of the information that is embedded in the data. The relationship between the variance and information is that, the larger the variance carried by the vector, the larger the dispersion of the data points along it, and larger the dispersion along the vector, the more information it contains.\n",
    "\n",
    "PCA algorithm performs **dimensionality reduction** on the data set. ***Dimensionality reduction implies, we attempt to capture the essence of a multivariate dataset into fewer number of variables that would explain the required result***.\n",
    "\n",
    "So subsequent to generation of individual PCs, only those PCs are selected that explain the maximum variation thereby capturing the essence of the analysis. Machine learning algorithms implementing the concept of Principal Component Analysis (PCA) can be used to this end. A PCA algorithm accepts all of the incoming interest data as an input, and it processes the data so that as an output we get a certain set of interest rate tenor points which contribute to around say 97% to 98% of the risk of our interest rate sensitive portfolio. This is technically termed as dimensionality reduction as mentioned earlier. This substantially reduces the load on the system resources, since now, the system will use only those tenor points as have been chosen by the PCA algorithm. This enables freeing up of valuable system resources which now can be used for other productive purposes. PCA can be implemented in Python.\n",
    "\n",
    "PCA algorithm involves the following steps:\n",
    "\n",
    "1. **Standardization**:\n",
    "As we have already seen in this notebook, this step involves standardizing the input variables so that they may be used in the PCA analysis. Accuracy of PCA algorithm is a function of the accuracy of inputs. So, in the very first step of the algorithm, we perform a standardization which results in all variables getting transformed to a same scale. This builds the foundation of the PCA analysis.\n",
    "2. **Covariance matrix**:\n",
    "This step involves computation of a covariance matrix which gives the relationship between the input variables. A covariance matrix is a symmetric matrix. With the diagonal elements giving the correlation, and the off-diagonal elements giving the covariance between variables. Depending on the sign of the covariance, the algorithm understands whether there is a direct or an inverse relation between variables. This step is important with respect to dimensionality reduction, as highly correlated variables may convey redundant information so the algorithm may appropriately handle these during the analysis.\n",
    "3. **Eigen algebra**:\n",
    "Eigen values and Eigen vectors are calculated from the covariance matrix computed in the step above. Eigenvectors of the covariance matrix are the direction of the axes where there is most variance i.e. most information. These are the PCs. Eigen values are the coefficients attached to the eigen vectors; they explain the amount of variance carried by each of the PCs. By ranking the eigen vectors in the order of their eigen values, we get the PCs in order of their significance. Next, we choose only the top 2 or top 3 PCs. The reason being, that its these top 2 or top 3 PCs that explain most of the variance in the data. Generally, top 3 PCs explain more than 97% of the variance in the data. Speaking about **Interest Rate Risk**, out of the top 3 PCs the first PC is attributed to account for parallel shifts in the rates, second PC is attributed to account for steepening of the curve, third PC is attributed to account for bowing of the interest rate curve. We also compute the standard deviations of the same called as factor loadings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we have to load the file 'MarketData.csv'\n",
    "#\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>3m</th>\n",
       "      <th>6m</th>\n",
       "      <th>1y</th>\n",
       "      <th>2y</th>\n",
       "      <th>3y</th>\n",
       "      <th>4y</th>\n",
       "      <th>5y</th>\n",
       "      <th>7y</th>\n",
       "      <th>10y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.71</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.56</td>\n",
       "      <td>8.71</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.94</td>\n",
       "      <td>9.04</td>\n",
       "      <td>8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.17</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.72</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.96</td>\n",
       "      <td>9.05</td>\n",
       "      <td>8.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.68</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.18</td>\n",
       "      <td>8.54</td>\n",
       "      <td>8.69</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.92</td>\n",
       "      <td>9.02</td>\n",
       "      <td>8.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.22</td>\n",
       "      <td>8.55</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.93</td>\n",
       "      <td>9.03</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.96</td>\n",
       "      <td>8.22</td>\n",
       "      <td>8.55</td>\n",
       "      <td>8.70</td>\n",
       "      <td>8.76</td>\n",
       "      <td>8.93</td>\n",
       "      <td>9.03</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date    3m    6m    1y    2y    3y    4y    5y    7y   10y\n",
       "0     1  7.71  7.90  8.16  8.56  8.71  8.75  8.94  9.04  8.76\n",
       "1     2  7.75  7.93  8.17  8.58  8.72  8.76  8.96  9.05  8.76\n",
       "2     3  7.68  7.90  8.18  8.54  8.69  8.75  8.92  9.02  8.73\n",
       "3     4  7.69  7.93  8.22  8.55  8.70  8.76  8.93  9.03  8.75\n",
       "4     5  7.69  7.96  8.22  8.55  8.70  8.76  8.93  9.03  8.75"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path + 'MarketData.csv', sep=',')\n",
    "x = pd.DataFrame(data)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x.drop(axis=1,columns=['Date'])\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of the data\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor loadings can be calculated as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326333</td>\n",
       "      <td>-0.332127</td>\n",
       "      <td>-0.335253</td>\n",
       "      <td>-0.336409</td>\n",
       "      <td>-0.336407</td>\n",
       "      <td>-0.336645</td>\n",
       "      <td>-0.336749</td>\n",
       "      <td>-0.331415</td>\n",
       "      <td>-0.328477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544483</td>\n",
       "      <td>0.481083</td>\n",
       "      <td>0.254532</td>\n",
       "      <td>0.026220</td>\n",
       "      <td>-0.094576</td>\n",
       "      <td>-0.232499</td>\n",
       "      <td>-0.195293</td>\n",
       "      <td>-0.439282</td>\n",
       "      <td>-0.335432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.420097</td>\n",
       "      <td>-0.089586</td>\n",
       "      <td>0.239718</td>\n",
       "      <td>0.367905</td>\n",
       "      <td>0.368985</td>\n",
       "      <td>0.193024</td>\n",
       "      <td>0.162056</td>\n",
       "      <td>-0.254609</td>\n",
       "      <td>-0.598480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.483507</td>\n",
       "      <td>0.155548</td>\n",
       "      <td>0.552238</td>\n",
       "      <td>0.194323</td>\n",
       "      <td>-0.150791</td>\n",
       "      <td>-0.285729</td>\n",
       "      <td>-0.310074</td>\n",
       "      <td>-0.106423</td>\n",
       "      <td>0.432952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.077813</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>-0.068074</td>\n",
       "      <td>-0.189461</td>\n",
       "      <td>-0.066528</td>\n",
       "      <td>0.199704</td>\n",
       "      <td>0.509370</td>\n",
       "      <td>-0.714587</td>\n",
       "      <td>0.371542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.265687</td>\n",
       "      <td>-0.373126</td>\n",
       "      <td>-0.286407</td>\n",
       "      <td>0.548879</td>\n",
       "      <td>0.267776</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.390429</td>\n",
       "      <td>-0.316872</td>\n",
       "      <td>0.286948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.156875</td>\n",
       "      <td>-0.313745</td>\n",
       "      <td>0.089269</td>\n",
       "      <td>0.445102</td>\n",
       "      <td>-0.474288</td>\n",
       "      <td>-0.417560</td>\n",
       "      <td>0.506926</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>-0.081522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.113533</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>-0.269583</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.562689</td>\n",
       "      <td>-0.692176</td>\n",
       "      <td>0.238268</td>\n",
       "      <td>0.028055</td>\n",
       "      <td>0.078216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.269520</td>\n",
       "      <td>-0.579435</td>\n",
       "      <td>0.541370</td>\n",
       "      <td>-0.417573</td>\n",
       "      <td>0.318277</td>\n",
       "      <td>-0.142704</td>\n",
       "      <td>0.020379</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>0.028572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.326333 -0.332127 -0.335253 -0.336409 -0.336407 -0.336645 -0.336749   \n",
       "1  0.544483  0.481083  0.254532  0.026220 -0.094576 -0.232499 -0.195293   \n",
       "2 -0.420097 -0.089586  0.239718  0.367905  0.368985  0.193024  0.162056   \n",
       "3 -0.483507  0.155548  0.552238  0.194323 -0.150791 -0.285729 -0.310074   \n",
       "4 -0.077813  0.031178 -0.068074 -0.189461 -0.066528  0.199704  0.509370   \n",
       "5  0.265687 -0.373126 -0.286407  0.548879  0.267776  0.002223 -0.390429   \n",
       "6  0.156875 -0.313745  0.089269  0.445102 -0.474288 -0.417560  0.506926   \n",
       "7 -0.113533  0.227273 -0.269583 -0.058133  0.562689 -0.692176  0.238268   \n",
       "8  0.269520 -0.579435  0.541370 -0.417573  0.318277 -0.142704  0.020379   \n",
       "\n",
       "          7         8  \n",
       "0 -0.331415 -0.328477  \n",
       "1 -0.439282 -0.335432  \n",
       "2 -0.254609 -0.598480  \n",
       "3 -0.106423  0.432952  \n",
       "4 -0.714587  0.371542  \n",
       "5 -0.316872  0.286948  \n",
       "6  0.089134 -0.081522  \n",
       "7  0.028055  0.078216  \n",
       "8 -0.035621  0.028572  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=9)\n",
    "pca.fit(X)\n",
    "factor_loading = pca.components_\n",
    "df_factor_loading = pd.DataFrame(factor_loading)\n",
    "df_factor_loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor loadings explain the relation between the impact of a factor on interest rates at respective tenor points.\n",
    "In PCA we also analyse the amount of dispersion explained by each of the PCs. Now we will see which PC contributes how much amount of variance/dispersion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.406078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.931193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.183464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.125015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0  96.406078\n",
       "1   1.931193\n",
       "2   1.183464\n",
       "3   0.242575\n",
       "4   0.125015\n",
       "5   0.059899\n",
       "6   0.032387\n",
       "7   0.013283\n",
       "8   0.006106"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance percent of each PC\n",
    "variance_percent_df = pd.DataFrame(data=pca.explained_variance_)\n",
    "variance_ratio_df = pd.DataFrame(data=pca.explained_variance_ratio_)\n",
    "variance_ratio_df = variance_ratio_df * 100\n",
    "variance_ratio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table alongside, we observe that PC1 explains almost 96% of the total variation, and PC2 explains close to 1.95% of total variation. Therefore, rather than using all PCs in the subsequent calculation, we can only use PC1 and PC2 in further calculation as these two components explain close to 98% of the total variance. \n",
    "\n",
    "- PC1 corresponds to the roughly the parallel shift in the yield curve. \n",
    "- PC2 corresponds to roughly a steepening in the yield curve.\n",
    "\n",
    "This is in-line with the theory of fixed income risk measurement which states that majority of the movement in the price of a bond is explained by the parallel shift in the yield curve and the residual movements in the price is explained by steepening and curvature of the interest rate curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abhyankar Ameya**, \"*Exploring Risk Analytics using PCA with Python*\", [Medium](https://abhyankar-ameya.medium.com/exploring-risk-analytics-using-pca-with-python-3aca369cbfe4), data files for the interest rate example and further details about the python code can be dowloaded from the github repository of the author [here](https://github.com/Ameya1983/TheAlchemist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": "3",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
