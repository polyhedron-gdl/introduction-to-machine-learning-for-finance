{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/qf-workshop-2021/introduction-to-machine-learning/blob/main/1_notebooks/introduction-to-machine-learning.ipynb\">\n",
    "        <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised and Unsupervised Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model makes a prediction by simply computing a weighted\n",
    "sum of the input features, plus a constant called the *bias* term (also called the *intercept*\n",
    "term):\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\hat y$ is the predicted value;\n",
    "- $n$ is the number of features;\n",
    "- $x_i$ is the $i^{th}$ feature value;\n",
    "- $\\theta_j$ is the $j^{th}$ model parameter (including the bias term $\\theta_0$ and the feature weights $\\theta_1, \\theta_2, \\dots, \\theta_n$\n",
    "\n",
    "Training a model means setting its parameters so that the model best fits the training set. For this purpose, we first need a measure of how well (or poorly) the model fits the training data. The most common performance measure of a regression model is the Root Mean Square Error (RMSE), therefore, to train a Linear Regression model, you need to find the value of $\\theta$ that minimizes the RMSE. In practice, it is simpler to minimize the Mean Square Error (MSE) than the RMSE, and it leads to the same result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - Predicting Iowa House Prices (from Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages \n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting packages\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as clrs\n",
    "\n",
    "# Kmeans algorithm from scikit-learn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Problem\n",
    "\n",
    "The objective is to predict the prices of house in Iowa from features. We have 800 observations in training set, 600 in validation set, and 508 in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features\n",
    "\n",
    "Categorical features are features where there are a number of non-numerical alternatives. We can define a dummy variable for each alternative. The variable equals 1 if the alternative is true and zero otherwise. This is known as **one-hot encoding**.\n",
    "But sometimes we do not have to do this because there is a natural ordering of variables. For example in this problem one of the categorical features is concerned with the basement quality as indicated by the ceiling height. The categories are:\n",
    "\n",
    "- *Excellent (< 100 inches)*\n",
    "- *Good (90-99 inches)*\n",
    "- *Typical (80-89 inches)*\n",
    "- *Fair (70-79 inches)*\n",
    "- *Poor (< 70 inches)*\n",
    "- *No Basement*\n",
    "\n",
    "This is an example of a categorical variable where *there is* a natural ordering. We created a new variable that had a values of 5, 4, 3, 2, 1 and 0 for the above six categories respectively.\n",
    "\n",
    "The other categorical features specifies the location of the house as in one of 25 neighborhoods. We introduce 25 dummy variables with a one-hot encoding. The dummy variable equals one for an observation if the neighborhood is that in which the house is located and zero otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data (J. C. Hull, 2019, Chapter 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the regression techniques discussed in this chapter we will use a total of 48 feature. 21 are numerical and two are categorical and to this we had, as discussed above, 25 categorical variables for the neighborhoods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>OLDTown</th>\n",
       "      <th>SWISU</th>\n",
       "      <th>Sawyer</th>\n",
       "      <th>SawyerW</th>\n",
       "      <th>Somerst</th>\n",
       "      <th>StoneBr</th>\n",
       "      <th>Timber</th>\n",
       "      <th>Veenker</th>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <th>Sale Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.199572</td>\n",
       "      <td>0.652747</td>\n",
       "      <td>-0.512407</td>\n",
       "      <td>1.038851</td>\n",
       "      <td>0.875754</td>\n",
       "      <td>0.597837</td>\n",
       "      <td>-0.937245</td>\n",
       "      <td>-0.482464</td>\n",
       "      <td>-0.808820</td>\n",
       "      <td>1.203988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286942</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.2253</td>\n",
       "      <td>-0.214192</td>\n",
       "      <td>-0.268378</td>\n",
       "      <td>-0.127929</td>\n",
       "      <td>-0.152629</td>\n",
       "      <td>-0.091644</td>\n",
       "      <td>0.584308</td>\n",
       "      <td>0.358489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.072005</td>\n",
       "      <td>-0.072527</td>\n",
       "      <td>2.189741</td>\n",
       "      <td>0.136810</td>\n",
       "      <td>-0.432225</td>\n",
       "      <td>1.218528</td>\n",
       "      <td>-0.635042</td>\n",
       "      <td>0.490326</td>\n",
       "      <td>0.276358</td>\n",
       "      <td>-0.789421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286942</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.2253</td>\n",
       "      <td>-0.214192</td>\n",
       "      <td>-0.268378</td>\n",
       "      <td>-0.127929</td>\n",
       "      <td>-0.152629</td>\n",
       "      <td>10.905682</td>\n",
       "      <td>0.584308</td>\n",
       "      <td>0.008849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111026</td>\n",
       "      <td>0.652747</td>\n",
       "      <td>-0.512407</td>\n",
       "      <td>0.972033</td>\n",
       "      <td>0.827310</td>\n",
       "      <td>0.095808</td>\n",
       "      <td>-0.296754</td>\n",
       "      <td>-0.329118</td>\n",
       "      <td>-0.637758</td>\n",
       "      <td>1.231999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286942</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.2253</td>\n",
       "      <td>-0.214192</td>\n",
       "      <td>-0.268378</td>\n",
       "      <td>-0.127929</td>\n",
       "      <td>-0.152629</td>\n",
       "      <td>-0.091644</td>\n",
       "      <td>0.584308</td>\n",
       "      <td>0.552733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.077551</td>\n",
       "      <td>0.652747</td>\n",
       "      <td>-0.512407</td>\n",
       "      <td>-1.901135</td>\n",
       "      <td>-0.722887</td>\n",
       "      <td>-0.520319</td>\n",
       "      <td>-0.057698</td>\n",
       "      <td>-0.722067</td>\n",
       "      <td>-0.528171</td>\n",
       "      <td>0.975236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286942</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.2253</td>\n",
       "      <td>-0.214192</td>\n",
       "      <td>-0.268378</td>\n",
       "      <td>-0.127929</td>\n",
       "      <td>-0.152629</td>\n",
       "      <td>-0.091644</td>\n",
       "      <td>-0.577852</td>\n",
       "      <td>-0.528560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444919</td>\n",
       "      <td>1.378022</td>\n",
       "      <td>-0.512407</td>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.730423</td>\n",
       "      <td>0.481458</td>\n",
       "      <td>-0.170461</td>\n",
       "      <td>0.209990</td>\n",
       "      <td>-0.036366</td>\n",
       "      <td>1.668495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286942</td>\n",
       "      <td>-0.136621</td>\n",
       "      <td>-0.2253</td>\n",
       "      <td>-0.214192</td>\n",
       "      <td>-0.268378</td>\n",
       "      <td>-0.127929</td>\n",
       "      <td>-0.152629</td>\n",
       "      <td>-0.091644</td>\n",
       "      <td>0.584308</td>\n",
       "      <td>0.895898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  BsmtFinSF1  \\\n",
       "0 -0.199572     0.652747    -0.512407   1.038851      0.875754    0.597837   \n",
       "1 -0.072005    -0.072527     2.189741   0.136810     -0.432225    1.218528   \n",
       "2  0.111026     0.652747    -0.512407   0.972033      0.827310    0.095808   \n",
       "3 -0.077551     0.652747    -0.512407  -1.901135     -0.722887   -0.520319   \n",
       "4  0.444919     1.378022    -0.512407   0.938624      0.730423    0.481458   \n",
       "\n",
       "   BsmtUnfSF  TotalBsmtSF  1stFlrSF  2ndFlrSF  ...   OLDTown     SWISU  \\\n",
       "0  -0.937245    -0.482464 -0.808820  1.203988  ... -0.286942 -0.136621   \n",
       "1  -0.635042     0.490326  0.276358 -0.789421  ... -0.286942 -0.136621   \n",
       "2  -0.296754    -0.329118 -0.637758  1.231999  ... -0.286942 -0.136621   \n",
       "3  -0.057698    -0.722067 -0.528171  0.975236  ... -0.286942 -0.136621   \n",
       "4  -0.170461     0.209990 -0.036366  1.668495  ... -0.286942 -0.136621   \n",
       "\n",
       "   Sawyer   SawyerW   Somerst   StoneBr    Timber    Veenker  Bsmt Qual  \\\n",
       "0 -0.2253 -0.214192 -0.268378 -0.127929 -0.152629  -0.091644   0.584308   \n",
       "1 -0.2253 -0.214192 -0.268378 -0.127929 -0.152629  10.905682   0.584308   \n",
       "2 -0.2253 -0.214192 -0.268378 -0.127929 -0.152629  -0.091644   0.584308   \n",
       "3 -0.2253 -0.214192 -0.268378 -0.127929 -0.152629  -0.091644  -0.577852   \n",
       "4 -0.2253 -0.214192 -0.268378 -0.127929 -0.152629  -0.091644   0.584308   \n",
       "\n",
       "   Sale Price  \n",
       "0    0.358489  \n",
       "1    0.008849  \n",
       "2    0.552733  \n",
       "3   -0.528560  \n",
       "4    0.895898  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both features and target have already been scaled: mean = 0; SD = 1\n",
    "data = pd.read_csv(path + 'Houseprice_data_scaled.csv') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all check how many records we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available data = 2908\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of available data = \"  + str(len(data.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting we emphasize the need to divide all available data into three parts: a **training set**, a **validation set** and a **test set**. The training set is used to determine parameters for trial models. The validation set is used to determine the extent to chich the models created from the training set generalize to new data. Finally, the test set is used as a final estimate of the accuracy of the chosen model. \n",
    "\n",
    "We had 2908 observations. We split this as follows: 1800 in the training set, 600 in the validation set and 508 in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 1800 data items are training set; the next 600 are the validation set\n",
    "train = data.iloc[:1800] \n",
    "val = data.iloc[1800:2400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now procede to create **labels** and **features**. As we have already said, the labels are the values of the target that is to be predicted, in this case the 'Sale Price', and we indicate that whit 'y':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val = train[['Sale Price']], val[['Sale Price']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and dummy variables were scaled using the Z-score method. Also the target values (i.e. the house prices) have been scaled with the Z-score method. The features are the variables from which the predictions are to be made and, in this case, can be obtained simply dropping the column 'Sale Price' from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train.drop('Sale Price', axis=1), val.drop('Sale Price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
       "       'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'TotRmsAbvGrd',\n",
       "       'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', 'Blmngtn', 'Blueste', 'BrDale', 'BrkSide', 'ClearCr',\n",
       "       'CollgCr', 'Crawfor', 'Edwards', 'Gilbert', 'IDOTRR', 'MeadowV',\n",
       "       'Mitchel', 'Names', 'NoRidge', 'NPkVill', 'NriddgHt', 'NWAmes',\n",
       "       'OLDTown', 'SWISU', 'Sawyer', 'SawyerW', 'Somerst', 'StoneBr', 'Timber',\n",
       "       'Veenker', 'Bsmt Qual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.06335941e-11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intercept</td>\n",
       "      <td>LotArea</td>\n",
       "      <td>OverallQual</td>\n",
       "      <td>OverallCond</td>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>...</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>OLDTown</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>Somerst</td>\n",
       "      <td>StoneBr</td>\n",
       "      <td>Timber</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Bsmt Qual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.06336e-11</td>\n",
       "      <td>0.0789996</td>\n",
       "      <td>0.214395</td>\n",
       "      <td>0.0964787</td>\n",
       "      <td>0.160799</td>\n",
       "      <td>0.0253524</td>\n",
       "      <td>0.0914664</td>\n",
       "      <td>-0.0330798</td>\n",
       "      <td>0.138199</td>\n",
       "      <td>0.152786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0517591</td>\n",
       "      <td>-0.026499</td>\n",
       "      <td>-0.00414298</td>\n",
       "      <td>-0.0181341</td>\n",
       "      <td>-0.0282754</td>\n",
       "      <td>0.0275063</td>\n",
       "      <td>0.0630586</td>\n",
       "      <td>-0.00276173</td>\n",
       "      <td>0.00240311</td>\n",
       "      <td>0.0113115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1            2            3          4             5   \\\n",
       "0    intercept    LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd   \n",
       "1 -3.06336e-11  0.0789996     0.214395    0.0964787   0.160799     0.0253524   \n",
       "\n",
       "           6          7            8         9   ...         38        39  \\\n",
       "0  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  1stFlrSF  ...     NWAmes   OLDTown   \n",
       "1   0.0914664 -0.0330798     0.138199  0.152786  ... -0.0517591 -0.026499   \n",
       "\n",
       "           40         41         42         43         44          45  \\\n",
       "0       SWISU     Sawyer    SawyerW    Somerst    StoneBr      Timber   \n",
       "1 -0.00414298 -0.0181341 -0.0282754  0.0275063  0.0630586 -0.00276173   \n",
       "\n",
       "           46         47  \n",
       "0     Veenker  Bsmt Qual  \n",
       "1  0.00240311  0.0113115  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = pd.DataFrame(\n",
    "    [\n",
    "        ['intercept'] + list(X_train.columns),\n",
    "        list(lr.intercept_) + list(lr.coef_[0])\n",
    "    ]\n",
    ")\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-3.06336e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0.0789996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0.214395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0.0964787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.160799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>0.0253524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>0.0914664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>-0.0330798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.138199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>0.152786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.132765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.161303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>-0.0208076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.0171941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>-0.0835202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.0832203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.0282578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.0379971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>0.0518093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>0.0208337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>0.0340982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>0.00682223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blmngtn</th>\n",
       "      <td>-0.0184305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blueste</th>\n",
       "      <td>-0.0129214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrDale</th>\n",
       "      <td>-0.0246262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrkSide</th>\n",
       "      <td>0.0207618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClearCr</th>\n",
       "      <td>-0.00737828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CollgCr</th>\n",
       "      <td>-0.00675362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crawfor</th>\n",
       "      <td>0.0363235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edwards</th>\n",
       "      <td>-0.000690065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilbert</th>\n",
       "      <td>-0.00834022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDOTRR</th>\n",
       "      <td>-0.00153683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeadowV</th>\n",
       "      <td>-0.016418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>-0.0284821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Names</th>\n",
       "      <td>-0.0385057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoRidge</th>\n",
       "      <td>0.0515626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPkVill</th>\n",
       "      <td>-0.0219519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NriddgHt</th>\n",
       "      <td>0.12399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NWAmes</th>\n",
       "      <td>-0.0517591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLDTown</th>\n",
       "      <td>-0.026499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWISU</th>\n",
       "      <td>-0.00414298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sawyer</th>\n",
       "      <td>-0.0181341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SawyerW</th>\n",
       "      <td>-0.0282754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somerst</th>\n",
       "      <td>0.0275063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StoneBr</th>\n",
       "      <td>0.0630586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timber</th>\n",
       "      <td>-0.00276173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veenker</th>\n",
       "      <td>0.00240311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <td>0.0113115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         1\n",
       "0                         \n",
       "intercept     -3.06336e-11\n",
       "LotArea          0.0789996\n",
       "OverallQual       0.214395\n",
       "OverallCond      0.0964787\n",
       "YearBuilt         0.160799\n",
       "YearRemodAdd     0.0253524\n",
       "BsmtFinSF1       0.0914664\n",
       "BsmtUnfSF       -0.0330798\n",
       "TotalBsmtSF       0.138199\n",
       "1stFlrSF          0.152786\n",
       "2ndFlrSF          0.132765\n",
       "GrLivArea         0.161303\n",
       "FullBath        -0.0208076\n",
       "HalfBath         0.0171941\n",
       "BedroomAbvGr    -0.0835202\n",
       "TotRmsAbvGrd     0.0832203\n",
       "Fireplaces       0.0282578\n",
       "GarageCars       0.0379971\n",
       "GarageArea       0.0518093\n",
       "WoodDeckSF       0.0208337\n",
       "OpenPorchSF      0.0340982\n",
       "EnclosedPorch   0.00682223\n",
       "Blmngtn         -0.0184305\n",
       "Blueste         -0.0129214\n",
       "BrDale          -0.0246262\n",
       "BrkSide          0.0207618\n",
       "ClearCr        -0.00737828\n",
       "CollgCr        -0.00675362\n",
       "Crawfor          0.0363235\n",
       "Edwards       -0.000690065\n",
       "Gilbert        -0.00834022\n",
       "IDOTRR         -0.00153683\n",
       "MeadowV          -0.016418\n",
       "Mitchel         -0.0284821\n",
       "Names           -0.0385057\n",
       "NoRidge          0.0515626\n",
       "NPkVill         -0.0219519\n",
       "NriddgHt           0.12399\n",
       "NWAmes          -0.0517591\n",
       "OLDTown          -0.026499\n",
       "SWISU          -0.00414298\n",
       "Sawyer          -0.0181341\n",
       "SawyerW         -0.0282754\n",
       "Somerst          0.0275063\n",
       "StoneBr          0.0630586\n",
       "Timber         -0.00276173\n",
       "Veenker         0.00240311\n",
       "Bsmt Qual        0.0113115"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataFrame with corresponding feature and its respective coefficients\n",
    "coeffs = pd.DataFrame(\n",
    "    [\n",
    "        ['intercept'] + list(X_train.columns),\n",
    "        list(lr.intercept_) + list(lr.coef_[0])\n",
    "    ]\n",
    ").transpose().set_index(0)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coeffs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11401526431246334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_t=lr.predict(X_train)\n",
    "mse(y_train,pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11702499460121657"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_v=lr.predict(X_val)\n",
    "mse(y_val,pred_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data we are considering it turns out that this regression model generalizes well. The mean squared error for the validation set was only a little higher than that for the training set. However linear regression with no regularization leads to some strange results because of the correlation between features. For example it makes no sense that the weights for number of full bathrooms and number of bedrooms are negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5347396038733939"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = X_train['GrLivArea']\n",
    "x2 = X_train['BedroomAbvGr']\n",
    "x1.corr(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Ridge\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try using Ridge regression with different values of the hyperparameter $\\lambda$. The following code shows the effect of this parameter on the prediction error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11703284346091342\n",
      "0.11710797319752984\n",
      "0.11723952924901117\n",
      "0.11741457158889518\n",
      "0.1176238406871145\n",
      "0.11825709631198021\n",
      "0.11900057469147927\n",
      "0.1225464999629295\n",
      "0.13073599680747128\n"
     ]
    }
   ],
   "source": [
    "# The alpha used by Python's ridge should be the lambda in Hull's book times the number of observations\n",
    "alphas=[0.01*1800, 0.02*1800, 0.03*1800, 0.04*1800, 0.05*1800, 0.075*1800,0.1*1800,0.2*1800, 0.4*1800]\n",
    "mses=[]\n",
    "for alpha in alphas:\n",
    "    ridge=Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train,y_train)\n",
    "    pred=ridge.predict(X_val)\n",
    "    mses.append(mse(y_val,pred))\n",
    "    print(mse(y_val,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x193b3ed8c08>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alphas, mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the prediction error increases as $\\lambda$ increases. Values of $\\lambda$ in the range $0$ to $0.1$ might be reasonably be considered because prediction errors increases only slightly when $\\lambda$ is in this range. However it turns out that the improvement in the model is quite small for these values of $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lasso\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.05)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we produce results for alpha=0.05 which corresponds to lambda=0.1 in Hull's book\n",
    "lasso = Lasso(alpha=0.05)\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-1.25303e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>0.0443042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>0.298079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.0520907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>0.0644712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>0.115875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>0.10312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>0.0322946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.297065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>0.0204043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.027512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>0.0664096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>0.00102883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>0.00215018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blmngtn</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blueste</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrDale</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrkSide</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClearCr</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CollgCr</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crawfor</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edwards</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gilbert</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDOTRR</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeadowV</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Names</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoRidge</th>\n",
       "      <td>0.013209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPkVill</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NriddgHt</th>\n",
       "      <td>0.0842993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NWAmes</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLDTown</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWISU</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sawyer</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SawyerW</th>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somerst</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StoneBr</th>\n",
       "      <td>0.0168153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timber</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veenker</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bsmt Qual</th>\n",
       "      <td>0.0202754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         1\n",
       "0                         \n",
       "intercept     -1.25303e-11\n",
       "LotArea          0.0443042\n",
       "OverallQual       0.298079\n",
       "OverallCond              0\n",
       "YearBuilt        0.0520907\n",
       "YearRemodAdd     0.0644712\n",
       "BsmtFinSF1        0.115875\n",
       "BsmtUnfSF               -0\n",
       "TotalBsmtSF        0.10312\n",
       "1stFlrSF         0.0322946\n",
       "2ndFlrSF                 0\n",
       "GrLivArea         0.297065\n",
       "FullBath                 0\n",
       "HalfBath                 0\n",
       "BedroomAbvGr            -0\n",
       "TotRmsAbvGrd             0\n",
       "Fireplaces       0.0204043\n",
       "GarageCars        0.027512\n",
       "GarageArea       0.0664096\n",
       "WoodDeckSF      0.00102883\n",
       "OpenPorchSF     0.00215018\n",
       "EnclosedPorch           -0\n",
       "Blmngtn                 -0\n",
       "Blueste                 -0\n",
       "BrDale                  -0\n",
       "BrkSide                  0\n",
       "ClearCr                  0\n",
       "CollgCr                 -0\n",
       "Crawfor                  0\n",
       "Edwards                 -0\n",
       "Gilbert                  0\n",
       "IDOTRR                  -0\n",
       "MeadowV                 -0\n",
       "Mitchel                 -0\n",
       "Names                   -0\n",
       "NoRidge           0.013209\n",
       "NPkVill                 -0\n",
       "NriddgHt         0.0842993\n",
       "NWAmes                  -0\n",
       "OLDTown                 -0\n",
       "SWISU                   -0\n",
       "Sawyer                  -0\n",
       "SawyerW                 -0\n",
       "Somerst                  0\n",
       "StoneBr          0.0168153\n",
       "Timber                   0\n",
       "Veenker                  0\n",
       "Bsmt Qual        0.0202754"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame with corresponding feature and its respective coefficients\n",
    "coeffs = pd.DataFrame(\n",
    "    [\n",
    "        ['intercept'] + list(X_train.columns),\n",
    "        list(lasso.intercept_) + list(lasso.coef_)\n",
    "    ]\n",
    ").transpose().set_index(0)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso with different levels of alpha and its mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.005 - mse = 0.116548\n",
      "lambda = 0.010 - mse = 0.116827\n",
      "lambda = 0.015 - mse = 0.118033\n",
      "lambda = 0.020 - mse = 0.120128\n",
      "lambda = 0.025 - mse = 0.123015\n",
      "lambda = 0.030 - mse = 0.126462\n",
      "lambda = 0.040 - mse = 0.133492\n",
      "lambda = 0.045 - mse = 0.137016\n",
      "lambda = 0.050 - mse = 0.140172\n"
     ]
    }
   ],
   "source": [
    "# We now consider different lambda values. The alphas are half the lambdas\n",
    "alphas=[0.01/2, 0.02/2, 0.03/2, 0.04/2, 0.05/2, 0.06/2, 0.08/2, 0.09/2, 0.1/2]\n",
    "mses=[]\n",
    "for alpha in alphas:\n",
    "    lasso=Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train,y_train)\n",
    "    pred=lasso.predict(X_val)\n",
    "    mses.append(mse(y_val,pred))\n",
    "    print(\"lambda = \" + '{:<05}'.format(alpha) + \" - mse = \" + str(round(mse(y_val, pred),6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x193b3f7fc08>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alphas, mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression leads to more interesting results. In the plot above you can see how the error in the validation set changes as tha value of the lasso $\\lambda$ increases. For small values of $\\lambda$ the error is actually less than when $\\lambda = 0$ but as $\\lambda$ increases beyond about $0.03$ the error starts to increase. A value of $\\lambda = 0.04$ could be chosen.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John C. Hull, **Machine Learning in Business: An Introduction to the World of Data Science**, Amazon, 2019.\n",
    "\n",
    "Paul Wilmott, **Machine Learning: An Applied Mathematics Introduction**, Panda Ohana Publishing, 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
